{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#对销量采取平滑log处理\n",
    "is_get_82_model,lg,log = 0, 2, 1\n",
    "'*****************************************读取初赛和复赛数据*************************************************'\n",
    "pre_train_sale = pd.read_csv(r'D:\\学习\\ccf乘车预测\\第一名代码\\2019-CCF-BDCI-Car_sales-master\\fusaicar\\pre_data\\train_sales_data.csv')\n",
    "input_data  = pd.read_csv(r'D:\\学习\\ccf乘车预测\\第一名代码\\2019-CCF-BDCI-Car_sales-master\\fusaicar\\data\\train_sales_data.csv')\n",
    "final_data  = pd.read_csv(r'D:\\学习\\ccf乘车预测\\第一名代码\\2019-CCF-BDCI-Car_sales-master\\fusaicar\\data\\evaluation_public.csv')\n",
    "search_data = pd.read_csv(r'D:\\学习\\ccf乘车预测\\第一名代码\\2019-CCF-BDCI-Car_sales-master\\fusaicar\\data\\train_search_data.csv')\n",
    "#将复赛新车型标记出来\n",
    "pre_model = list(set(list(pre_train_sale['model'])))\n",
    "input_data['new_model'] = list(map(lambda x: 1 if pre_model.count(x) == 0 else 0,input_data['model']))\n",
    "final_data['new_model'] = list(map(lambda x: 1 if pre_model.count(x) == 0 else 0,final_data['model']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(data):\n",
    "    #对数据进行预处理，将各个属性转为数值特征\n",
    "    data['date'] = list(map(lambda x,y:str(x)+\".\"+str(y),data['regYear'],data['regMonth']))\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    if 'forecastVolum' in list(data.columns):\n",
    "        data = data.drop(['forecastVolum'],axis=1)\n",
    "    if 'province' in list(data.columns):\n",
    "        pro_label = dict(zip(sorted(list(set(data['province']))), range(0, len(set(data['province'])))))\n",
    "    model_label = dict(zip(sorted(list(set(data['model']))), range(0, len(set(data['model'])))))\n",
    "    if 'bodyType' in list(data.columns):\n",
    "       body_label = dict(zip(sorted(list(set(data['bodyType']))), range(0, len(set(data['bodyType'])))))\n",
    "       data['body_id'] = data['bodyType'].map(body_label)\n",
    "       data=data.drop(['bodyType'],axis=1)\n",
    "    if 'province' in list(data.columns):\n",
    "        data['pro_id'] = data['province'].map(pro_label)\n",
    "    data['model_id'] = data['model'].map(model_label)\n",
    "    data=data.drop(['regYear','regMonth','model'],axis=1)\n",
    "    if 'province' in list(data.columns):\n",
    "         data=data.drop(['adcode','province'],axis=1)\n",
    "    data['month_id'] = data['date'].apply(lambda x : x.month)\n",
    "    data['sales_year'] = data['date'].apply(lambda x : x.year)\n",
    "    data['time_id'] = list(map(lambda x,y:(x-2016)*12+y,data['sales_year'],data['month_id']))\n",
    "    data=data.drop(['date'],axis=1).rename(columns={'salesVolume':'label'})\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data  = prepare(input_data)\n",
    "final_data  = prepare(final_data)\n",
    "search_data = prepare(search_data)\n",
    "#将预测的文件拼接到数据集中并补全bodytype\n",
    "pivot = pd.pivot_table(input_data,index=['model_id','body_id'])\n",
    "pivot = pd.DataFrame(pivot).reset_index()[['model_id','body_id']]\n",
    "final_data = pd.merge(final_data,pivot,on='model_id',how='left')\n",
    "input_data = pd.merge(input_data,search_data,how='left',on=['pro_id','model_id','sales_year','month_id','time_id'])\n",
    "input_data = pd.concat([input_data,final_data])\n",
    "input_data['salesVolume'] = input_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_id</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>model_id</th>\n",
       "      <th>month_id</th>\n",
       "      <th>new_model</th>\n",
       "      <th>popularity</th>\n",
       "      <th>pro_id</th>\n",
       "      <th>sales_year</th>\n",
       "      <th>time_id</th>\n",
       "      <th>salesVolume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>292.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>292.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>466.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1594.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>466.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2370.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>610.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3562.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>206.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>503.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3476.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>236.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>236.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3635.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7182.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>3635.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>450.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1163.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>876.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3670.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>876.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>253.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>926.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2973.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>537.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3483.0</td>\n",
       "      <td>13</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>537.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>650.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3167.0</td>\n",
       "      <td>14</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>635.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2190.0</td>\n",
       "      <td>15</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>635.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>525.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1666.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>462.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1357.0</td>\n",
       "      <td>17</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>791.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2808.0</td>\n",
       "      <td>18</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>791.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>19</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>298.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1558.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2118.0</td>\n",
       "      <td>21</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>389.0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1519.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1161.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>260.0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>449.0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>449.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>757.0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3757.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>757.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>275.0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1378.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>890.0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>890.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>387.0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1425.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>387.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7186</th>\n",
       "      <td>3</td>\n",
       "      <td>7275.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7187</th>\n",
       "      <td>3</td>\n",
       "      <td>7276.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7188</th>\n",
       "      <td>3</td>\n",
       "      <td>7277.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7189</th>\n",
       "      <td>3</td>\n",
       "      <td>7278.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7190</th>\n",
       "      <td>3</td>\n",
       "      <td>7279.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7191</th>\n",
       "      <td>3</td>\n",
       "      <td>7280.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7192</th>\n",
       "      <td>3</td>\n",
       "      <td>7281.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7193</th>\n",
       "      <td>3</td>\n",
       "      <td>7282.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7194</th>\n",
       "      <td>3</td>\n",
       "      <td>7283.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7195</th>\n",
       "      <td>3</td>\n",
       "      <td>7284.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7196</th>\n",
       "      <td>3</td>\n",
       "      <td>7285.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7197</th>\n",
       "      <td>3</td>\n",
       "      <td>7286.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7198</th>\n",
       "      <td>3</td>\n",
       "      <td>7287.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7199</th>\n",
       "      <td>3</td>\n",
       "      <td>7288.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7200</th>\n",
       "      <td>3</td>\n",
       "      <td>7289.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7201</th>\n",
       "      <td>3</td>\n",
       "      <td>7290.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7202</th>\n",
       "      <td>3</td>\n",
       "      <td>7291.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7203</th>\n",
       "      <td>3</td>\n",
       "      <td>7292.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7204</th>\n",
       "      <td>3</td>\n",
       "      <td>7293.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7205</th>\n",
       "      <td>3</td>\n",
       "      <td>7294.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7206</th>\n",
       "      <td>3</td>\n",
       "      <td>7295.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7207</th>\n",
       "      <td>3</td>\n",
       "      <td>7296.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7208</th>\n",
       "      <td>3</td>\n",
       "      <td>7297.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7209</th>\n",
       "      <td>3</td>\n",
       "      <td>7298.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7210</th>\n",
       "      <td>3</td>\n",
       "      <td>7299.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7211</th>\n",
       "      <td>3</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7212</th>\n",
       "      <td>3</td>\n",
       "      <td>7301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7213</th>\n",
       "      <td>3</td>\n",
       "      <td>7302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7214</th>\n",
       "      <td>3</td>\n",
       "      <td>7303.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7215</th>\n",
       "      <td>3</td>\n",
       "      <td>7304.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>2018</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50512 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      body_id      id   label  model_id  month_id  new_model  popularity  \\\n",
       "0           2     NaN   292.0        20         1          0      1479.0   \n",
       "1           2     NaN   466.0        20         1          0      1594.0   \n",
       "2           2     NaN   257.0        20         1          0      1479.0   \n",
       "3           2     NaN   408.0        20         1          0      2370.0   \n",
       "4           2     NaN   610.0        20         1          0      3562.0   \n",
       "5           2     NaN   206.0        20         1          0      1314.0   \n",
       "6           2     NaN   503.0        20         1          0      3476.0   \n",
       "7           2     NaN   236.0        20         1          0      1422.0   \n",
       "8           2     NaN  3635.0        20         1          0      7182.0   \n",
       "9           2     NaN   450.0        20         1          0      1163.0   \n",
       "10          2     NaN   876.0        20         1          0      3670.0   \n",
       "11          2     NaN   253.0        20         1          0       926.0   \n",
       "12          2     NaN   306.0        20         1          0      2973.0   \n",
       "13          2     NaN   537.0        20         1          0      3483.0   \n",
       "14          2     NaN   650.0        20         1          0      3167.0   \n",
       "15          2     NaN   635.0        20         1          0      2190.0   \n",
       "16          2     NaN   525.0        20         1          0      1666.0   \n",
       "17          2     NaN   462.0        20         1          0      1357.0   \n",
       "18          2     NaN   791.0        20         1          0      2808.0   \n",
       "19          2     NaN   195.0        20         1          0       682.0   \n",
       "20          2     NaN   298.0        20         1          0      1558.0   \n",
       "21          2     NaN   309.0        20         1          0      2118.0   \n",
       "22          3     NaN   389.0        21         1          0      1519.0   \n",
       "23          3     NaN   306.0        21         1          0      1161.0   \n",
       "24          3     NaN   260.0        21         1          0      1340.0   \n",
       "25          3     NaN   449.0        21         1          0      2388.0   \n",
       "26          3     NaN   757.0        21         1          0      3757.0   \n",
       "27          3     NaN   275.0        21         1          0      1378.0   \n",
       "28          3     NaN   890.0        21         1          0      3643.0   \n",
       "29          3     NaN   387.0        21         1          0      1425.0   \n",
       "...       ...     ...     ...       ...       ...        ...         ...   \n",
       "7186        3  7275.0     NaN        54         4          1         NaN   \n",
       "7187        3  7276.0     NaN        54         4          1         NaN   \n",
       "7188        3  7277.0     NaN        54         4          1         NaN   \n",
       "7189        3  7278.0     NaN        54         4          1         NaN   \n",
       "7190        3  7279.0     NaN        54         4          1         NaN   \n",
       "7191        3  7280.0     NaN        54         4          1         NaN   \n",
       "7192        3  7281.0     NaN        54         4          1         NaN   \n",
       "7193        3  7282.0     NaN        54         4          1         NaN   \n",
       "7194        3  7283.0     NaN        81         4          1         NaN   \n",
       "7195        3  7284.0     NaN        81         4          1         NaN   \n",
       "7196        3  7285.0     NaN        81         4          1         NaN   \n",
       "7197        3  7286.0     NaN        81         4          1         NaN   \n",
       "7198        3  7287.0     NaN        81         4          1         NaN   \n",
       "7199        3  7288.0     NaN        81         4          1         NaN   \n",
       "7200        3  7289.0     NaN        81         4          1         NaN   \n",
       "7201        3  7290.0     NaN        81         4          1         NaN   \n",
       "7202        3  7291.0     NaN        81         4          1         NaN   \n",
       "7203        3  7292.0     NaN        81         4          1         NaN   \n",
       "7204        3  7293.0     NaN        81         4          1         NaN   \n",
       "7205        3  7294.0     NaN        81         4          1         NaN   \n",
       "7206        3  7295.0     NaN        81         4          1         NaN   \n",
       "7207        3  7296.0     NaN        81         4          1         NaN   \n",
       "7208        3  7297.0     NaN        81         4          1         NaN   \n",
       "7209        3  7298.0     NaN        81         4          1         NaN   \n",
       "7210        3  7299.0     NaN        81         4          1         NaN   \n",
       "7211        3  7300.0     NaN        81         4          1         NaN   \n",
       "7212        3  7301.0     NaN        81         4          1         NaN   \n",
       "7213        3  7302.0     NaN        81         4          1         NaN   \n",
       "7214        3  7303.0     NaN        81         4          1         NaN   \n",
       "7215        3  7304.0     NaN        81         4          1         NaN   \n",
       "\n",
       "      pro_id  sales_year  time_id  salesVolume  \n",
       "0          0        2016        1        292.0  \n",
       "1          1        2016        1        466.0  \n",
       "2          2        2016        1        257.0  \n",
       "3          3        2016        1        408.0  \n",
       "4          4        2016        1        610.0  \n",
       "5          5        2016        1        206.0  \n",
       "6          6        2016        1        503.0  \n",
       "7          7        2016        1        236.0  \n",
       "8          8        2016        1       3635.0  \n",
       "9          9        2016        1        450.0  \n",
       "10        10        2016        1        876.0  \n",
       "11        11        2016        1        253.0  \n",
       "12        12        2016        1        306.0  \n",
       "13        13        2016        1        537.0  \n",
       "14        14        2016        1        650.0  \n",
       "15        15        2016        1        635.0  \n",
       "16        16        2016        1        525.0  \n",
       "17        17        2016        1        462.0  \n",
       "18        18        2016        1        791.0  \n",
       "19        19        2016        1        195.0  \n",
       "20        20        2016        1        298.0  \n",
       "21        21        2016        1        309.0  \n",
       "22         0        2016        1        389.0  \n",
       "23         1        2016        1        306.0  \n",
       "24         2        2016        1        260.0  \n",
       "25         3        2016        1        449.0  \n",
       "26         4        2016        1        757.0  \n",
       "27         5        2016        1        275.0  \n",
       "28         6        2016        1        890.0  \n",
       "29         7        2016        1        387.0  \n",
       "...      ...         ...      ...          ...  \n",
       "7186      14        2018       28          NaN  \n",
       "7187      15        2018       28          NaN  \n",
       "7188      16        2018       28          NaN  \n",
       "7189      17        2018       28          NaN  \n",
       "7190      18        2018       28          NaN  \n",
       "7191      19        2018       28          NaN  \n",
       "7192      20        2018       28          NaN  \n",
       "7193      21        2018       28          NaN  \n",
       "7194       0        2018       28          NaN  \n",
       "7195       1        2018       28          NaN  \n",
       "7196       2        2018       28          NaN  \n",
       "7197       3        2018       28          NaN  \n",
       "7198       4        2018       28          NaN  \n",
       "7199       5        2018       28          NaN  \n",
       "7200       6        2018       28          NaN  \n",
       "7201       7        2018       28          NaN  \n",
       "7202       8        2018       28          NaN  \n",
       "7203       9        2018       28          NaN  \n",
       "7204      10        2018       28          NaN  \n",
       "7205      11        2018       28          NaN  \n",
       "7206      12        2018       28          NaN  \n",
       "7207      13        2018       28          NaN  \n",
       "7208      14        2018       28          NaN  \n",
       "7209      15        2018       28          NaN  \n",
       "7210      16        2018       28          NaN  \n",
       "7211      17        2018       28          NaN  \n",
       "7212      18        2018       28          NaN  \n",
       "7213      19        2018       28          NaN  \n",
       "7214      20        2018       28          NaN  \n",
       "7215      21        2018       28          NaN  \n",
       "\n",
       "[50512 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stat_feature(df_,month):   \n",
    "    data = df_.copy()\n",
    "    stat_feat = []\n",
    "    start = int((month-24)/3)*2\n",
    "    start += int((month-24)/4)\n",
    "    start = start-1 if start >=1 else start\n",
    "    '历史月销量' \n",
    "    for last in range(1,17):  \n",
    "        tmp=data.copy()\n",
    "        tmp['time_id'] = list(map(lambda x:x+last+start if x+last+start<=28 else -1,tmp['time_id']))\n",
    "        tmp = tmp[~tmp['time_id'].isin([-1])][['label','time_id','pro_id','model_id','body_id']]\n",
    "        tmp = tmp.rename(columns={'label':'last_{0}_sale'.format(last)})\n",
    "        data = pd.merge(data,tmp,how='left',on=['time_id','pro_id','model_id','body_id'])\n",
    "        if last <= 6:\n",
    "            stat_feat.append('last_{0}_sale'.format(last)) \n",
    "    '历史月popularity'\n",
    "    for last in range(1,17):  \n",
    "        tmp=data.copy()\n",
    "        tmp['time_id']=list(map(lambda x:x+last+start if x+last+start<=28 else -1,tmp['time_id']))\n",
    "        tmp=tmp[~tmp['time_id'].isin([-1])][['popularity','time_id','pro_id','model_id','body_id']]\n",
    "        tmp=tmp.rename(columns={'popularity':'last_{0}_popularity'.format(last)})\n",
    "        data=pd.merge(data,tmp,how='left',on=['time_id','pro_id','model_id','body_id'])\n",
    "        if last<=6 or (last>=11 and last<=13):\n",
    "            stat_feat.append('last_{0}_popularity'.format(last)) \n",
    "\n",
    "    '半年销量等统计特征'\n",
    "    data['1_6_sum'] = data.loc[:,'last_1_sale':'last_6_sale'].sum(1)\n",
    "    data['1_6_mea'] = data.loc[:,'last_1_sale':'last_6_sale'].mean(1)\n",
    "    data['1_6_max'] = data.loc[:,'last_1_sale':'last_6_sale'].max(1)\n",
    "    data['1_6_min'] = data.loc[:,'last_1_sale':'last_6_sale'].min(1)\n",
    "    data['jidu_1_3_sum']  = data.loc[:,'last_1_sale':'last_3_sale'].sum(1)\n",
    "    data['jidu_4_6_sum']  = data.loc[:,'last_4_sale':'last_6_sale'].sum(1)\n",
    "    data['jidu_1_3_mean'] = data.loc[:,'last_1_sale':'last_3_sale'].mean(1)\n",
    "    data['jidu_4_6_mean'] = data.loc[:,'last_4_sale':'last_6_sale'].mean(1)\n",
    "    sales_stat_feat = ['1_6_sum','1_6_mea','1_6_max','1_6_min','jidu_1_3_sum','jidu_4_6_sum','jidu_1_3_mean','jidu_4_6_mean']\n",
    "    stat_feat = stat_feat + sales_stat_feat\n",
    "    \n",
    "    'model_pro趋势特征'\n",
    "    data['1_2_diff'] = data['last_1_sale'] - data['last_2_sale']\n",
    "    data['1_3_diff'] = data['last_1_sale'] - data['last_3_sale']\n",
    "    data['2_3_diff'] = data['last_2_sale'] - data['last_3_sale']\n",
    "    data['2_4_diff'] = data['last_2_sale'] - data['last_4_sale']\n",
    "    data['3_4_diff'] = data['last_3_sale'] - data['last_4_sale']\n",
    "    data['3_5_diff'] = data['last_3_sale'] - data['last_5_sale']\n",
    "    data['jidu_1_2_diff'] = data['jidu_1_3_sum'] - data['jidu_4_6_sum']\n",
    "    trend_stat_feat = ['1_2_diff','1_3_diff','2_3_diff','2_4_diff','3_4_diff','3_5_diff','jidu_1_2_diff']\n",
    "    stat_feat = stat_feat + trend_stat_feat\n",
    "\n",
    "    '春节月'\n",
    "    yanhaicity={1,2,5,7,9,13,16,17}\n",
    "    data['is_yanhai']  = list(map(lambda x:1 if x in yanhaicity else 0,data['pro_id']))\n",
    "    data['is_chunjie'] = list(map(lambda x:1 if x==2 or x==13 or x==26 else 0,data['time_id']))\n",
    "    data['is_chunjie_before'] = list(map(lambda x:1 if x==1 or x==12 or x==25 else 0,data['time_id']))\n",
    "    data['is_chunjie_late']   = list(map(lambda x:1 if x==3 or x==14 or x==27 else 0,data['time_id']))\n",
    "    month_city_stat_feat = ['is_chunjie','is_chunjie_before','is_chunjie_late','is_yanhai']\n",
    "    stat_feat = stat_feat + month_city_stat_feat\n",
    "    \n",
    "    '两个月销量差值'\n",
    "    'model 前两个月的销量差值'\n",
    "    pivot = pd.pivot_table(data,index=['model_id'],values='1_2_diff',aggfunc=np.sum)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'1_2_diff':'model_1_2_diff_sum'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=['model_id'],how='left')\n",
    "    'pro 前两个月的销量差值'\n",
    "    pivot = pd.pivot_table(data,index=['pro_id'],values='1_2_diff',aggfunc=np.sum)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'1_2_diff':'pro_1_2_diff_sum'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=['pro_id'],how='left')\n",
    "    'model,pro 前两个月的销量差值'\n",
    "    pivot = pd.pivot_table(data,index=['pro_id','model_id'],values='1_2_diff',aggfunc=np.sum)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'1_2_diff':'model_pro_1_2_diff_sum'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=['pro_id','model_id'],how='left')\n",
    "    pivot = pd.pivot_table(data,index=['pro_id','model_id'],values='1_2_diff',aggfunc=np.mean)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'1_2_diff':'model_pro_1_2_diff_mean'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=['pro_id','model_id'],how='left')\n",
    "    two_month_stat_feat = ['model_1_2_diff_sum','pro_1_2_diff_sum','model_pro_1_2_diff_sum','model_pro_1_2_diff_mean']\n",
    "    stat_feat = stat_feat + two_month_stat_feat\n",
    "\n",
    "    '月份'\n",
    "    count_month = [31,28,31,30,31,30,31,31,30,31,30,31]\n",
    "    data['count_month'] = list(map(lambda x:count_month[int(x-1)],data['month_id']))\n",
    "    jiaqibiao = [[11,12,8,10,10,9,10,8,9,13,8,9],[12,9,8,11,10,8,10,8,8,14,8,10],[9,11,9,11]]\n",
    "    data['count_jiaqi'] = list(map(lambda x,y:jiaqibiao[int(x-2016)][int(y-1)],data['sales_year'],data['month_id']))\n",
    "    stat_feat.append('count_month')\n",
    "    stat_feat.append('count_jiaqi')\n",
    "    \n",
    "    '环比'\n",
    "    data['huanbi_1_2'] = data['last_1_sale'] / data['last_2_sale']\n",
    "    data['huanbi_2_3'] = data['last_2_sale'] / data['last_3_sale']\n",
    "    data['huanbi_3_4'] = data['last_3_sale'] / data['last_4_sale']\n",
    "    data['huanbi_4_5'] = data['last_4_sale'] / data['last_5_sale']\n",
    "    data['huanbi_5_6'] = data['last_5_sale'] / data['last_6_sale']\n",
    "    ring_ratio_stat_feat = ['huanbi_1_2','huanbi_2_3','huanbi_3_4','huanbi_5_6']\n",
    "    stat_feat = stat_feat + ring_ratio_stat_feat\n",
    "\n",
    "    'add环比比'\n",
    "    data['huanbi_1_2_2_3'] = data['huanbi_1_2'] / data['huanbi_2_3']\n",
    "    data['huanbi_2_3_3_4'] = data['huanbi_2_3'] / data['huanbi_3_4']\n",
    "    data['huanbi_3_4_4_5'] = data['huanbi_3_4'] - data['huanbi_4_5']\n",
    "    data['huanbi_4_5_5_6'] = data['huanbi_4_5'] - data['huanbi_5_6']\n",
    "    two_ring_ratio_stat_feat = ['huanbi_1_2_2_3','huanbi_2_3_3_4','huanbi_3_4_4_5','huanbi_4_5_5_6']\n",
    "    stat_feat = stat_feat + two_ring_ratio_stat_feat\n",
    "\n",
    "    '该月该省份bodytype销量的占比与涨幅'\n",
    "    for i in range(1,7):\n",
    "        last_time='last_{0}_sale'.format(i)\n",
    "        pivot = pd.pivot_table(data,index=['time_id','pro_id','body_id'],values=last_time,aggfunc=np.sum)\n",
    "        pivot = pd.DataFrame(pivot).rename(columns={last_time:'pro_body_last_{0}_sale_sum'.format(i)}).reset_index()\n",
    "        data  = pd.merge(data,pivot,on=['time_id','pro_id','body_id'],how='left')\n",
    "        data['last_{0}_sale_ratio_pro_body_last_{0}_sale_sum'.format(i,i)]=list(map(lambda x,y:x/y if y!=0 else 0,data[last_time],data['pro_body_last_{0}_sale_sum'.format(i)]))\n",
    "        stat_feat.append('last_{0}_sale_ratio_pro_body_last_{0}_sale_sum'.format(i,i))\n",
    "        if i>=2:\n",
    "            data['last_{0}_{1}_sale_pro_body_diff'.format(i-1,i)] = data['last_{0}_sale_ratio_pro_body_last_{0}_sale_sum'.format(i-1)]-data['last_{0}_sale_ratio_pro_body_last_{0}_sale_sum'.format(i)]\n",
    "            stat_feat.append('last_{0}_{1}_sale_pro_body_diff'.format(i-1,i))\n",
    "\n",
    "    '该月该省份总销量占比与涨幅'\n",
    "    for i in range(1,7):\n",
    "        last_time = 'last_{0}_sale'.format(i)\n",
    "        pivot = pd.pivot_table(data,index=['time_id','pro_id'],values=last_time,aggfunc=np.sum)\n",
    "        pivot = pd.DataFrame(pivot).rename(columns={last_time:'pro__last_{0}_sale_sum'.format(i)}).reset_index()\n",
    "        data  = pd.merge(data,pivot,on=['time_id','pro_id'],how='left')\n",
    "        data['last_{0}_sale_ratio_pro_last_{0}_sale_sum'.format(i,i)]=list(map(lambda x,y:x/y if y!=0 else 0,data[last_time],data['pro__last_{0}_sale_sum'.format(i)]))\n",
    "        stat_feat.append('last_{0}_sale_ratio_pro_last_{0}_sale_sum'.format(i,i))\n",
    "        if i>=2:\n",
    "            data['model_last_{0}_{1}_sale_pro_diff'.format(i-1,i)] = data['last_{0}_sale_ratio_pro_last_{0}_sale_sum'.format(i-1)]-data['last_{0}_sale_ratio_pro_last_{0}_sale_sum'.format(i)]\n",
    "            stat_feat.append('model_last_{0}_{1}_sale_pro_diff'.format(i-1,i))\n",
    "\n",
    "    'popularity的涨幅占比'\n",
    "    data['huanbi_1_2popularity'] = (data['last_1_popularity'] - data['last_2_popularity']) / data['last_2_popularity']\n",
    "    data['huanbi_2_3popularity'] = (data['last_2_popularity'] - data['last_3_popularity']) / data['last_3_popularity']\n",
    "    data['huanbi_3_4popularity'] = (data['last_3_popularity'] - data['last_4_popularity']) / data['last_4_popularity']\n",
    "    data['huanbi_4_5popularity'] = (data['last_4_popularity'] - data['last_5_popularity']) / data['last_5_popularity']\n",
    "    data['huanbi_5_6popularity'] = (data['last_5_popularity'] - data['last_6_popularity']) / data['last_6_popularity']\n",
    "    popularity_ratio_stat_feat = ['huanbi_1_2popularity','huanbi_2_3popularity','huanbi_3_4popularity','huanbi_4_5popularity','huanbi_5_6popularity']\n",
    "    stat_feat = stat_feat + popularity_ratio_stat_feat\n",
    "\n",
    "    'popu_modelpopularity'\n",
    "    for i in range(1,7):\n",
    "        last_time='last_{0}_popularity'.format(i)\n",
    "        pivot = pd.pivot_table(data,index=['time_id','model_id'],values=last_time,aggfunc=np.sum)\n",
    "        pivot = pd.DataFrame(pivot).rename(columns={last_time:'model__last_{0}_popularity_sum'.format(i)}).reset_index()\n",
    "        data  = pd.merge(data,pivot,on=['time_id','model_id'],how='left')\n",
    "        data['last_{0}_popularity_ratio_model_last_{0}_popularity_sum'.format(i,i)]=list(map(lambda x,y:x/y if y!=0 else 0,data[last_time],data['model__last_{0}_popularity_sum'.format(i)]))\n",
    "        stat_feat.append('last_{0}_popularity_ratio_model_last_{0}_popularity_sum'.format(i,i))  \n",
    "\n",
    "    'body month 增长率popularitydemo4'\n",
    "    for i in range(1,7):\n",
    "        last_time='last_{0}_popularity'.format(i)\n",
    "        pivot = pd.pivot_table(data,index=['time_id','body_id'],values=last_time,aggfunc=np.sum)\n",
    "        pivot = pd.DataFrame(pivot).rename(columns={last_time:'body_last_{0}_popularity_sum'.format(i)}).reset_index()\n",
    "        data  = pd.merge(data,pivot,on=['time_id','body_id'],how='left')\n",
    "        data['last_{0}_popularity_ratio_body_last_{0}_popularity_sum'.format(i,i)]=list(map(lambda x,y:x/y if y!=0 else 0,data[last_time],data['body_last_{0}_popularity_sum'.format(i)]))\n",
    "        if i>=2:\n",
    "            data['last_{0}_{1}_popularity_body_diff'.format(i-1,i)] = (data['last_{0}_popularity_ratio_body_last_{0}_popularity_sum'.format(i-1)]-data['last_{0}_popularity_ratio_body_last_{0}_popularity_sum'.format(i)])/data['last_{0}_popularity_ratio_body_last_{0}_popularity_sum'.format(i)]\n",
    "            stat_feat.append('last_{0}_{1}_popularity_body_diff'.format(i-1,i)) \n",
    "\n",
    "    '同比一年前的增长'\n",
    "    data[\"increase16_4\"]=(data[\"last_16_sale\"] - data[\"last_4_sale\"]) / data[\"last_16_sale\"]\n",
    "    pivot = pd.pivot_table(data,index=[\"model_id\",\"time_id\"],values='last_12_sale',aggfunc=np.mean)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'last_12_sale':'mean_province'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"model_id\",\"time_id\"],how=\"left\")\n",
    "    pivot = pd.pivot_table(data,index=[\"model_id\",\"time_id\"],values='last_12_sale',aggfunc=np.min)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'last_12_sale':'min_province'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"model_id\",\"time_id\"],how=\"left\")\n",
    "    '前4个月车型的同比'\n",
    "    for i in range(1,5):\n",
    "        pivot = pd.pivot_table(data,index=[\"model_id\",\"time_id\"],values='last_{0}_sale'.format(i),aggfunc=np.mean)\n",
    "        pivot = pd.DataFrame(pivot).rename(columns={'last_{0}_sale'.format(i):'mean_province_{0}'.format(i)}).reset_index()\n",
    "        data  = pd.merge(data,pivot,on=[\"model_id\",\"time_id\"],how=\"left\")\n",
    "        pivot = pd.pivot_table(data,index=[\"model_id\",\"time_id\"],values='last_{0}_sale'.format(i+12),aggfunc=np.mean)\n",
    "        pivot = pd.DataFrame(pivot).rename(columns={'last_{0}_sale'.format(i+12):'mean_province_{0}'.format(i+12)}).reset_index()\n",
    "        data  = pd.merge(data,pivot,on=[\"model_id\",\"time_id\"],how=\"left\")\n",
    "    data[\"increase_mean_province_14_2\"] = (data[\"mean_province_14\"] - data[\"mean_province_2\"]) / data[\"mean_province_14\"]\n",
    "    data[\"increase_mean_province_13_1\"] = (data[\"mean_province_13\"] - data[\"mean_province_1\"]) / data[\"mean_province_13\"]\n",
    "    data[\"increase_mean_province_16_4\"] = (data[\"mean_province_16\"] - data[\"mean_province_4\"]) / data[\"mean_province_16\"]\n",
    "    data[\"increase_mean_province_15_3\"] = (data[\"mean_province_15\"] - data[\"mean_province_3\"]) / data[\"mean_province_15\"]\n",
    "    new_stat_feat = [\"mean_province\",\"min_province\",\"increase16_4\",\"increase_mean_province_15_3\",\"increase_mean_province_16_4\",\"increase_mean_province_14_2\",\"increase_mean_province_13_1\"]\n",
    "    \n",
    "    return data,stat_feat + new_stat_feat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_type():   \n",
    "    model = lgb.LGBMRegressor(\n",
    "            num_leaves=2**5-1, reg_alpha=0.25, reg_lambda=0.25, objective='mse',\n",
    "            max_depth=-1, learning_rate=0.05, min_child_samples=5, random_state=2019,\n",
    "            n_estimators=600, subsample=0.9, colsample_bytree=0.7,\n",
    "            )\n",
    "    return model\n",
    "\n",
    "def get_train_model(df_, m, m_type,features, num_feat, cate_feat):\n",
    "    \n",
    "    df = df_.copy()\n",
    "    # 数据集划分\n",
    "    all_idx   = df['time_id'].between(7 , m-1)\n",
    "    test_idx  = df['time_id'].between(m , m  )\n",
    "    #初始化model    \n",
    "    model = get_model_type()\n",
    "    model.fit(df[all_idx][features], df[all_idx]['label'], categorical_feature=cate_feat,verbose=100)\n",
    "    df['forecastVolum'] = model.predict(df[features]) \n",
    "    sub = df[test_idx][['id']]\n",
    "    sub['forecastVolum'] = df[test_idx]['forecastVolum'].apply(lambda x: 2.0 if x < 0 else x)\n",
    "    return sub\n",
    "\n",
    "def LGB(input_data,is_get_82_model):\n",
    "    #采用lightgbm销量进行预测，这里采取分月预测的形式，分别预测1 2 3 4月\n",
    "    #同时，分别对初赛和复赛的车型进行分别预测，在预测初赛的车型时只使用初赛的数据，在预测复赛新加的车型时使用全部数据\n",
    "    if is_get_82_model == 0:\n",
    "        input_data = input_data[input_data['new_model']==0]\n",
    "    input_data['label'] = list(map(lambda x : x if x==np.NAN else math.log(x+1,lg),input_data['label']))\n",
    "    input_data['salesVolume'] = list(map(lambda x : x if x==np.NAN else math.log(x+1,lg),input_data['salesVolume']))\n",
    "    input_data['jidu_id'] = ((input_data['month_id']-1)/3+1).map(int)\n",
    "    '******************************分月预测************************************************************'\n",
    "    for month in [25,26,27,28]: \n",
    "        m_type = 'lgb' \n",
    "        data_df, stat_feat = get_stat_feature(input_data,month)\n",
    "        num_feat = ['sales_year']+stat_feat\n",
    "        cate_feat = ['pro_id','body_id','model_id','month_id','jidu_id']\n",
    "        for i in cate_feat:\n",
    "            data_df[i] = data_df[i].astype('category')\n",
    "        features = num_feat + cate_feat\n",
    "        sub = get_train_model(data_df, month, m_type, features, num_feat, cate_feat)   \n",
    "        input_data.loc[(input_data.time_id==month),  'salesVolume'] = sub['forecastVolum'].values\n",
    "        input_data.loc[(input_data.time_id==month),  'label'      ] = sub['forecastVolum'].values\n",
    "    input_data['salesVolume'] = list(map(lambda x : x if x==np.NAN else (lg**(x))-1, input_data['salesVolume']))\n",
    "    input_data['salesVolume'] = list(map(lambda x,y: x*0.95 if y == 26 else x,input_data['salesVolume'],input_data['time_id']))\n",
    "    input_data['salesVolume'] = list(map(lambda x,y: x*0.98 if y == 27 else x,input_data['salesVolume'],input_data['time_id']))\n",
    "    input_data['salesVolume'] = list(map(lambda x,y: x*0.90 if y == 28 else x,input_data['salesVolume'],input_data['time_id']))\n",
    "    sub = input_data.loc[(input_data.time_id >= 25),['id','salesVolume']]\n",
    "    sub.columns = ['id','forecastVolum']\n",
    "    sub['id'] = sub['id'].map(int)\n",
    "    sub['forecastVolum'] = sub['forecastVolum'].map(round)\n",
    "    return sub\n",
    "\n",
    "def get_lgb_ans(input_data):\n",
    "    #对销量进行预测，并返回最终lgb预测的结果\n",
    "    print('use 60 models to train lgb model...')\n",
    "    sub_60=LGB(input_data,0)\n",
    "    print('use 82 models to train lgb model...')\n",
    "    sub_82=LGB(input_data,1)\n",
    "    input_data = pd.merge(input_data,sub_60,on='id',how='left')\n",
    "    input_data = pd.merge(input_data,sub_82,on='id',how='left')\n",
    "    input_data = input_data.loc[input_data.time_id>=25,['id','forecastVolum_x','forecastVolum_y']]\n",
    "    input_data = input_data.fillna(-1)\n",
    "    input_data['forecastVolum'] = list(map(lambda x,y:y if x==-1 else x,input_data['forecastVolum_x'],input_data['forecastVolum_y']))\n",
    "    input_data = input_data[['id','forecastVolum']]\n",
    "    input_data['id'] = input_data['id'].map(int)\n",
    "    input_data['forecastVolum'] = input_data['forecastVolum'].map(int)\n",
    "    return input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blend lgb and rule...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "'********************************************rule训练***********************************************'\n",
    "def exp_smooth(df,alpha=0.97,base=50,start=1,win_size=3,t=24):\n",
    "    #使用三次指数平滑，根据历史销量值的变化趋势预测将来销量\n",
    "    #平滑因子，两次平滑之间间隔大小，起始编号，初始值的窗口大小，平滑周期\n",
    "    #第一次指数平滑\n",
    "    df[start+base-1] = 0\n",
    "    for i in range(win_size):\n",
    "        df[start+base-1] += df[start+i] / win_size\n",
    "    for i in range(t):\n",
    "        df[start+base+i] =  alpha * df[start+i] + (1 - alpha) * df[start+base+i-1]\n",
    "    #第二次指数平滑\n",
    "    df[start+2*base-1] = 0\n",
    "    for i in range(win_size):\n",
    "        df[start+2*base-1] += df[start+base+i] / win_size\n",
    "    for i in range(t):\n",
    "        df[start+2*base+i] =  alpha * df[start+base+i] + (1 - alpha) * df[start+2*base+i-1]\n",
    "    #第三次指数平滑\n",
    "    df[start+3*base-1] = 0\n",
    "    for i in range(win_size):\n",
    "        df[start+3*base-1] += df[start+2*base+i] / win_size\n",
    "    for i in range(t):\n",
    "        df[start+3*base+i] =  alpha * df[start+2*base+i] + (1 - alpha) * df[start+3*base+i-1]\n",
    "    #套入公式计算未来两个月的平滑值\n",
    "    t1,t2,t3 = df[start+base+t-1],df[start+2*base+t-1],df[start+3*base+t-1]\n",
    "    a = 3 * t1 - 3 * t2 + t3\n",
    "    b = ((6 - 5 * alpha) * t1 - 2 * (5 - 4 * alpha) * t2 + (4 - 3 * alpha) * t3) * alpha / (2 * (1 - alpha) ** 2)\n",
    "    c = (t1 - 2 * t2 + t3) * alpha ** 2 / (2 * (1 - alpha) ** 2)\n",
    "    for m in [25,26]:\n",
    "        df[m] = a + b * (m-t) + c * (m-t) ** 2\n",
    "    return df\n",
    "        \n",
    "def pre_rule():\n",
    "    #初赛60车型的规则方案\n",
    "    train = pd.read_csv(r'D:\\学习\\ccf乘车预测\\第一名代码\\2019-CCF-BDCI-Car_sales-master\\fusaicar\\pre_data\\train_sales_data.csv')\n",
    "    test = pd.read_csv(r'D:\\学习\\ccf乘车预测\\第一名代码\\2019-CCF-BDCI-Car_sales-master\\fusaicar\\pre_data\\evaluation_public.csv')\n",
    "    #对数据取对数，缩小销量之间的差距，降低极端值的影响\n",
    "    train['salesVolume'] = np.log(train['salesVolume'])\n",
    "    \n",
    "    #规则\n",
    "    train16 = train[(train['regYear'] == 2016)][['adcode', 'model', 'regMonth', 'salesVolume']]\n",
    "    train17 = train[(train['regYear'] == 2017)][['adcode', 'model', 'regMonth', 'salesVolume']]\n",
    "    #下半年的趋势\n",
    "    df16 = train16.loc[train16['regMonth'] > 6].groupby(['adcode', \"model\"], as_index=False)['salesVolume'].\\\n",
    "                                    agg({\"16_after_mean\": 'mean'}) # 按省份和车型统计均值\n",
    "    df17 = train17.loc[train17['regMonth'] > 6].groupby(['adcode', \"model\"], as_index=False)['salesVolume'].\\\n",
    "                                    agg({\"17_after_mean\": 'mean'})\n",
    "    df = pd.merge(df17, df16, on=['adcode', 'model'], how='inner')\n",
    "    df['after_factor'] = df['17_after_mean'] / df['16_after_mean'] # 17年均值除以16年均值得到趋势因子\n",
    "    #上半年的趋势\n",
    "    df16 = train16.loc[train16['regMonth'] <= 6].groupby(['adcode', \"model\"], as_index=False)['salesVolume'].\\\n",
    "                                    agg({\"16_front_mean\": 'mean'}) # 按省份和车型统计均值\n",
    "    df17 = train17.loc[train17['regMonth'] <= 6].groupby(['adcode', \"model\"], as_index=False)['salesVolume'].\\\n",
    "                                    agg({\"17_front_mean\": 'mean'})\n",
    "    df17 = df17.merge(df16, on=['adcode', 'model'], how='inner')\n",
    "    df['front_factor'] = df17['17_front_mean'] / df17['16_front_mean'] # 17年均值除以16年均值得到趋势因子\n",
    "    #总体趋势\n",
    "    df['factor'] = 0.35 * df['front_factor'] + 0.65 * df['after_factor']\n",
    "    # 在省份-车型作为主键的情况下，取出16年和17年的数据，共24个月\n",
    "    for m in range(1, 13):\n",
    "        df = pd.merge(df, train16[train16['regMonth'] == m][['adcode', 'model', 'salesVolume']], on=['adcode', 'model'], how='left').rename(columns={'salesVolume': m})\n",
    "        df = pd.merge(df, train17[train17['regMonth'] == m][['adcode', 'model', 'salesVolume']], on=['adcode', 'model'], how='left').rename(columns={'salesVolume': 12+m})\n",
    "    df = exp_smooth(df,alpha=0.97)\n",
    "    \n",
    "    res = pd.DataFrame()\n",
    "    tmp = df[['adcode', 'model']].copy()\n",
    "    #后处理\n",
    "    trend_factor = [0.985,0.965,0.99,0.985]\n",
    "    #开始预测\n",
    "    for i,m in enumerate([25,26,27,28]):\n",
    "        #以省份-车型作为主键，计算前年，去年，最近几个月的值，然后加权得到一个当前月份的预测值\n",
    "        last_year_base = 0.2 * df[m-13].values + 0.6 * df[m-12].values + 0.2 * df[m-11].values\n",
    "        if m == 25:\n",
    "            last_last_year_base = 0.8 * df[m-24] + 0.2 * df[m-23]\n",
    "        else:\n",
    "            last_last_year_base = 0.2 * df[m-25] + 0.6 * df[m-24] + 0.2 * df[m-23]\n",
    "        if m <=26:\n",
    "            near_base = 0.2 * df[m-3] + 0.2 * df[m-2] + 0.3 * df[m-1] + 0.3 * df[m]\n",
    "        else:\n",
    "            near_base = 0.2 * df[m-3] + 0.2 * df[m-2] + 0.6 * df[m-1]\n",
    "            \n",
    "        base = (last_year_base + near_base + last_last_year_base) / 3\n",
    "        tmp['forecastVolum'] = base * df['factor'] * trend_factor[i]\n",
    "        df[m] = tmp['forecastVolum']\n",
    "        tmp['regMonth'] = m-24\n",
    "        res = res.append(tmp, ignore_index=True)\n",
    "    \n",
    "    test = pd.merge(test[['id', 'adcode', 'model', 'regMonth']], res, how='left', on=['adcode', 'model', 'regMonth'])\n",
    "    test['forecastVolum'] = np.exp(test['forecastVolum'])\n",
    "    test.loc[test['forecastVolum'] < 0, 'forecastVolum'] = 0\n",
    "    return test[['id', 'forecastVolum']]\n",
    "\n",
    "\n",
    "    #总体趋势\n",
    "    def calc_factor(x):\n",
    "        L = list(x)\n",
    "        L = sorted(L)\n",
    "        return 0.6 * L[0] + 0.2 * L[1] + 0.1 * L[2] + 0.1 * L[3]\n",
    "    \n",
    "    df['factor'] = df[['3_factor','6_factor','9_factor','12_factor']].apply(lambda x:calc_factor(x),axis=1)\n",
    "    #对整体趋势进行后处理\n",
    "    df['factor'] = df['factor'].apply(lambda x:min(x,1.25))\n",
    "    df['factor'] = df['factor'].apply(lambda x:max(x,0.75))\n",
    "    \n",
    "    # 在省份-车型作为主键的情况下，取出16年和17年的数据，共24个月\n",
    "    for m in range(1, 13):\n",
    "        df = pd.merge(df, train16[train16['regMonth'] == m][['adcode', 'model', 'salesVolume']], on=['adcode', 'model'], how='left').rename(columns={'salesVolume': m})\n",
    "        df = pd.merge(df, train17[train17['regMonth'] == m][['adcode', 'model', 'salesVolume']], on=['adcode', 'model'], how='left').rename(columns={'salesVolume': 12+m})\n",
    "    df = exp_smooth(df,alpha=0.95)\n",
    "    \n",
    "    res = pd.DataFrame()\n",
    "    tmp = df[['adcode', 'model']].copy()\n",
    "    trend_factor = [0.985,0.965,0.99,0.985]\n",
    "    for i,m in enumerate([25,26,27,28]):\n",
    "        #以省份-车型作为主键，计算前年，去年，最近几个月的值，然后加权得到一个当前月份的预测值\n",
    "        last_year_base = 0.2 * df[m-13].values + 0.6 * df[m-12].values + 0.2 * df[m-11].values\n",
    "        if m == 25:\n",
    "            last_last_year_base = 0.8 * df[m-24] + 0.2 * df[m-23]\n",
    "        else:\n",
    "            last_last_year_base = 0.2 * df[m-25] + 0.6 * df[m-24] + 0.2 * df[m-23]\n",
    "        if m <=26:\n",
    "            near_base = 0.2 * df[m-3] + 0.2 * df[m-2] + 0.3 * df[m-1] + 0.3 * df[m]\n",
    "        else:\n",
    "            near_base = 0.2 * df[m-3] + 0.2 * df[m-2] + 0.6 * df[m-1]\n",
    "        \n",
    "        #按照三个的大小进行加权求和\n",
    "        temp = pd.DataFrame()\n",
    "        temp['near_base'] = near_base\n",
    "        temp['last_year_base'] = last_year_base\n",
    "        temp['last_last_year_base'] = last_last_year_base\n",
    "        def calc(row):\n",
    "            L = list(row)\n",
    "            L = sorted(L)\n",
    "            return 0.6 * L[0] + 0.2 * L[1] + 0.2 * L[2]\n",
    "        \n",
    "        temp['base'] = temp.apply(lambda row:calc(row),axis=1)\n",
    "        base = temp['base']\n",
    "        tmp['forecastVolum'] = base * df['factor'] * trend_factor[i]\n",
    "        df[m] = tmp['forecastVolum']\n",
    "        tmp['regMonth'] = m-24\n",
    "        res = res.append(tmp, ignore_index=True)\n",
    "    \n",
    "    test = pd.merge(test[['id', 'adcode', 'model', 'regMonth']], res, how='left', on=['adcode', 'model', 'regMonth'])\n",
    "    test['forecastVolum'] = np.exp(test['forecastVolum'])-1\n",
    "    test.loc[test['forecastVolum'] < 0, 'forecastVolum'] = 0\n",
    "    #初赛60个车型\n",
    "    pre_sub = pre_rule()\n",
    "    pre_test = pd.read_csv(r'D:\\学习\\ccf乘车预测\\第一名代码\\2019-CCF-BDCI-Car_sales-master\\fusaicar\\pre_data\\evaluation_public.csv')\n",
    "    pre_test['forecastVolum'] = pre_sub['forecastVolum']\n",
    "    pre_test.rename(columns={'forecastVolum':'pre_fore'},inplace=True)\n",
    "    test = test.merge(pre_test[['adcode','model','regMonth','pre_fore']],on=['adcode','model','regMonth'],how='left')\n",
    "    test.loc[~test.pre_fore.isnull(),'forecastVolum'] = test.loc[~test.pre_fore.isnull(),'pre_fore']\n",
    "    return test[['id', 'forecastVolum']]\n",
    "\n",
    "\n",
    "sub_rule = pre_rule()\n",
    "print('blend lgb and rule...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4e1243bd22c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'*********************************几何加权********************************'\n",
    "def fusion(sub,sub_rule,sub_lgb):\n",
    "    sub['rule'] = sub_rule['forecastVolum'].values\n",
    "    sub['lgb'] = sub_lgb['forecastVolum'].values\n",
    "    '60个车型1-4月融合'\n",
    "    sub['forecastVolum'] = -1\n",
    "    sub['forecastVolum'] = list(map(lambda x,y,z,m,f:(math.pow(x,0.40) * math.pow(y,0.60)) if z==0 and m==25 else f,sub['rule'],sub['lgb'],sub['new_model'],sub['time_id'],sub['forecastVolum']))\n",
    "    sub['forecastVolum'] = list(map(lambda x,y,z,m,f:(math.pow(x,0.40) * math.pow(y,0.60)) if z==0 and m==26 else f,sub['rule'],sub['lgb'],sub['new_model'],sub['time_id'],sub['forecastVolum']))\n",
    "    sub['forecastVolum'] = list(map(lambda x,y,z,m,f:(math.pow(x,0.50) * math.pow(y,0.50)) if z==0 and m==27 else f,sub['rule'],sub['lgb'],sub['new_model'],sub['time_id'],sub['forecastVolum']))\n",
    "    sub['forecastVolum'] = list(map(lambda x,y,z,m,f:(math.pow(x,0.40) * math.pow(y,0.60)) if z==0 and m==28 else f,sub['rule'],sub['lgb'],sub['new_model'],sub['time_id'],sub['forecastVolum']))\n",
    "    '22个车型1-4月融合'\n",
    "    sub['forecastVolum'] = list(map(lambda x,y,z,m,f:(math.pow(x,0.35) * math.pow(y,0.65)) if z==1 and m<=26 else f,sub['rule'],sub['lgb'],sub['new_model'],sub['time_id'],sub['forecastVolum']))\n",
    "    sub['forecastVolum'] = list(map(lambda x,y,z,m,f:(math.pow(x,0.40) * math.pow(y,0.60)) if z==1 and m==27 else f,sub['rule'],sub['lgb'],sub['new_model'],sub['time_id'],sub['forecastVolum']))\n",
    "    sub['forecastVolum'] = list(map(lambda x,y,z,m,f:(math.pow(x,0.40) * math.pow(y,0.60)) if z==1 and m==28 else f,sub['rule'],sub['lgb'],sub['new_model'],sub['time_id'],sub['forecastVolum']))\n",
    "    sub = sub[['id','forecastVolum']]\n",
    "    sub['id'] = sub['id'].map(int)\n",
    "    sub['forecastVolum'] = sub['forecastVolum'].map(int)\n",
    "    return sub\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    start = time.clock()\n",
    "    print('train lgb model...')\n",
    "    sub_lgb = get_lgb_ans(input_data)\n",
    "    print('train rule model...')\n",
    "    sub_rule = rule()\n",
    "    print('blend lgb and rule...')\n",
    "    sub = fusion(final_data, sub_rule, sub_lgb)\n",
    "    print('save final result...')\n",
    "    sub.to_csv(r'.\\sub\\sub.csv',index=False)\n",
    "    print('all procedures are over...')\n",
    "    print(\"time used: {0} seconds...\".format(int((time.clock() - start))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
